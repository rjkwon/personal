<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">

<title>Artificially Intelligent Thoughts &bull; Kwon.nyc</title>

<meta name="keywords" content="" />
<meta name="description" content="I am reading and hearing a lot of discourse about AI, machine learning, and more specifically, ChatGPT. It seems like a lot of people have a lot of opinions and things to say, and, like ChatGPT itself, they seem to be often wrong but never in doubt1. From what I can tell it seems like a lot of it is noise (generally when people make blanket statements about AI being bad and dangerous) but there is some real signal (generally when people use more precise verbiage, detailed use cases, and less sensationalized/more nuanced thoughts and conclusions such as potential for bias at a large scale with large language models and generative AI causing harm2).">
<meta name="author" content="">
<link rel="stylesheet" href="https://use.typekit.net/pyn4wgi.css">
<link rel="canonical" href="https://kwon.nyc/notes/artificially-intelligent-thoughts/" />
<link href="/assets/css/stylesheet.min.c86f6e59daa71e168a27498183b6b46caa3bb257c3bf902f76e5abfea96d8a81.css" integrity="sha256-yG9uWdqnHhaKJ0mBg7a0bKo7slfDv5AvduWr/qltioE=" rel="preload stylesheet"
    as="style">





<link rel="icon" href="https://kwon.nyc/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://kwon.nyc/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://kwon.nyc/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://kwon.nyc/apple-touch-icon.png">
<link rel="mask-icon" href="https://kwon.nyc/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.82.0" />


<meta property="og:title" content="Artificially Intelligent Thoughts" />
<meta property="og:description" content="I am reading and hearing a lot of discourse about AI, machine learning, and more specifically, ChatGPT. It seems like a lot of people have a lot of opinions and things to say, and, like ChatGPT itself, they seem to be often wrong but never in doubt1. From what I can tell it seems like a lot of it is noise (generally when people make blanket statements about AI being bad and dangerous) but there is some real signal (generally when people use more precise verbiage, detailed use cases, and less sensationalized/more nuanced thoughts and conclusions such as potential for bias at a large scale with large language models and generative AI causing harm2)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://kwon.nyc/notes/artificially-intelligent-thoughts/" /><meta property="article:section" content="notes" />
<meta property="article:published_time" content="2023-07-17T20:07:23-04:00" />
<meta property="article:modified_time" content="2023-07-17T20:07:23-04:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Artificially Intelligent Thoughts"/>
<meta name="twitter:description" content="I am reading and hearing a lot of discourse about AI, machine learning, and more specifically, ChatGPT. It seems like a lot of people have a lot of opinions and things to say, and, like ChatGPT itself, they seem to be often wrong but never in doubt1. From what I can tell it seems like a lot of it is noise (generally when people make blanket statements about AI being bad and dangerous) but there is some real signal (generally when people use more precise verbiage, detailed use cases, and less sensationalized/more nuanced thoughts and conclusions such as potential for bias at a large scale with large language models and generative AI causing harm2)."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://kwon.nyc/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Artificially Intelligent Thoughts",
      "item": "https://kwon.nyc/notes/artificially-intelligent-thoughts/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Artificially Intelligent Thoughts",
  "name": "Artificially Intelligent Thoughts",
  "description": "I am reading and hearing a lot of discourse about AI, machine learning, and more specifically, ChatGPT. It seems like a lot of people have a lot of opinions and things to say, and, like ChatGPT itself, they seem to be often wrong but never in doubt1. From what I can tell it seems like a lot of it is noise (generally when people make blanket statements about AI being bad and dangerous) but there is some real signal (generally when people use more precise verbiage, detailed use cases, and less sensationalized/more nuanced thoughts and conclusions such as potential for bias at a large scale with large language models and generative AI causing harm2).",
  "keywords": [
    
  ],
  "articleBody": "I am reading and hearing a lot of discourse about AI, machine learning, and more specifically, ChatGPT. It seems like a lot of people have a lot of opinions and things to say, and, like ChatGPT itself, they seem to be often wrong but never in doubt1. From what I can tell it seems like a lot of it is noise (generally when people make blanket statements about AI being bad and dangerous) but there is some real signal (generally when people use more precise verbiage, detailed use cases, and less sensationalized/more nuanced thoughts and conclusions such as potential for bias at a large scale with large language models and generative AI causing harm2).\nI‚Äôm in an information gathering stage right now (if the knowledge contained in the brain of the world‚Äôs leading expert on generative AI were represented by a complicated, elaborate, structurally sound bridge, my level of knowledge is a piece of rough lumber slapped between two puddles) so I don‚Äôt have much to add to the discourse that is of consequence.\n(But I‚Äôm going to, anyway, because this is the internet!) Based on my observations, it seems that many laypeople have made a lot of assumptions about ChatGPT without ever having used it or read any of the materials from OpenAI. I know because I did that. I heard about it and saw some of the more ridiculous examples on social media and some news sites and such, and rolled my eyes a bit.\nThen I figured if I‚Äôm going to be skeptical and pooh-pooh an emerging technology, it would probably be good for me to try it out so I can REALLY knock it. So I did!\nThe first thing I asked ChatGPT was what happened to the hole in the ozone layer3. Its response seemed right, and I used Wikipedia as the source of truth to verify facts, like confirming that the Montreal Protocol was in fact adopted in 1987. Because if ChatGPT had told me it was 1989, I would have believed it.\nBasically, it behaved mostly as I expected it to, and it was kind of useful, even with what I think is a healthy level of skepticism. I also appreciated that it‚Äôs pretty clear from the various disclaimers that it can be wrong, dangerous, biased, etc.\nI‚Äôve used it a lot more since then, asking for guidance on gift ideas for my notoriously hard-to-shop-for parents (I ended up going with my own initial idea, a gifted trip to the Korean spa, which actually was on ChatGPT‚Äôs list as well), something thoughtful to say to a coworker about to go off on parental leave (I mostly used my own words except one suggestion from ChatGPT to encourage them to take care of themselves in addition to the baby), and, what has become a pretty frequent use case for me at work lately, debugging SQL queries.\nMy early conclusion based on this limited experience (since May I have used ChatGPT approximately once a day on average) is that ChatGPT is mostly like any other tool‚Äîif it‚Äôs used for the right scenario in the right way, it can be incredibly useful, and if not, it can either just not add much value (best case scenario) or actively cause harm (worst case scenario). If I need a flathead screwdriver and all I have is a Philips head, the best decision I can make is to not use an inadequate and ineffective tool for my use case. Even if it‚Äôs the fanciest, most technologically advanced Philips head screwdriver, powered by drill with wifi connectivity, rainbow LED lighting, and adorned with sparkles, it doesn‚Äôt really matter if it‚Äôs not the tool that I need.\nWhat about disclosing use of ChatGPT as a tool? I think it depends. When I use it to debug a query, I don‚Äôt necessarily report that out when reporting on whatever finding I was investigating in the first place. (I have been excitedly telling anyone who will listen to me that I‚Äôve been using ChatGPT to debug my SQL queries (and then the cleaning staff are like, please, lady, I just want to mop this floor, okay?), for whatever that‚Äôs worth.) If it were being used for looking up and reporting on facts more quickly and easily (such as in publishing content), such as my ozone layer question, I would say it should absolutely be made explicitly clear that the content was generated using a tool developed based on a large language model and list the known limitations.\n(I had a flashback to working with this one thoracic surgeon who was really adept with the surgical robot and kind of took issue at the operating room staff for insisting that his patients' informed consent documentation state SPECIFIC permission to do a robotic-assisted wedge resection of left lung or whatever, instead of just wedge resection of left lung, and his argument was that he doesn‚Äôt have to get permission from the patient or even tell them if he were using a 11-blade versus a 15-blade; the robot was just a tool at his disposal and he as the surgeon had a responsibility to use the right tool for the job. I could see his point, but at the same time, it also didn‚Äôt seem totally right to not have a documented conversation with the patient that the robot would be used‚Äîand of course he had had that conversation, but the OR staff didn‚Äôt know that, so in that case maybe the informed consent was a tool being incorrectly used to represent all communication with the patient.)\nChatGPT seems to have the most potential for harm when there isn‚Äôt reliable feedback on its accuracy (or if the user does not care to actively seek feedback). With a prompt like ‚Äúdebug my SQL,‚Äù I can immediately judge the quality of the response because either my SQL runs or it doesn‚Äôt. For that lawyer who didn‚Äôt verify that the case law ChatGPT quoted was real before submitting it in a court filing‚Ä¶ oy.\nAnyway, obviously we need to learn more, but with the right guardrails and oversight, we shouldn‚Äôt fear technology. If anything, we should fear unchecked capitalism, because that‚Äôs what has ruined and snuffed out a lot of the exciting potential that technology offers, but that‚Äôs another story for another day.\n  That is a joke about surgeons, the original gangsters in perfecting the art of being confidently wrong. ‚Ü©Ô∏é\n I‚Äôm thinking of experts like Joy Buolamwini, Timnit Gebru, etc. ‚Ü©Ô∏é\n The context is that I was talking to someone in their 20s and mentioned something about Aqua Net and CFCs and how we made a hole in the ozone layer real bad in the 1980s but then we fixed it, and they were like, ‚ÄúWhat is the ozone layer?‚Äù After I recovered from a mild generation gap-induced heart attack, I turned to the internet for help. ‚Ü©Ô∏é\n   ",
  "wordCount" : "1150",
  "inLanguage": "en",
  "datePublished": "2023-07-17T20:07:23-04:00",
  "dateModified": "2023-07-17T20:07:23-04:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://kwon.nyc/notes/artificially-intelligent-thoughts/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Kwon.nyc",
    "logo": {
      "@type": "ImageObject",
      "url": "https://kwon.nyc/favicon.ico"
    }
  }
}
</script>




<script defer data-domain="kwon.nyc" src="https://plausible.io/js/plausible.js"></script>


</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: #1d1e20;
                --entry: #2e2e33;
                --primary: rgba(255, 255, 255, 0.84);
                --secondary: rgba(255, 255, 255, 0.56);
                --tertiary: rgba(255, 255, 255, 0.16);
                --content: rgba(255, 255, 255, 0.74);
                --hljs-bg: #2e2e33;
                --code-bg: #37383e;
                --border: #333;
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }
    </style>

</noscript>
<header class="header">
    <nav class="nav">
        <div class="logo">
            <img src="/images/logo.svg" alt="Í∂å" /> 
            
            <a href="https://kwon.nyc/" title="Artificially Intelligent Thoughts">Kwon.nyc</a>
            
        </div>
        <ul id="menu" onscroll="menu_on_scroll()">
            <li>
                <a href="https://kwon.nyc/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://kwon.nyc/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li><li>
                <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
<span id="moon">üï∂</span>
<span id="sun">üí°</span>
                </button>
                </span>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">

    <h1 class="post-title">
      Artificially Intelligent Thoughts
    </h1>
    <div class="post-meta">Monday, July 17, 2023


</div>
  </header> 

  <div class="post-content">
<p>I am reading and hearing a lot of discourse about AI, machine learning, and more specifically, ChatGPT. It seems like a lot of people have a lot of opinions and things to say, and, like ChatGPT itself, they seem to be often wrong but never in doubt<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. From what I can tell it seems like a lot of it is noise (generally when people make blanket statements about AI being bad and dangerous) but there is some real signal (generally when people use more precise verbiage, detailed use cases, and less sensationalized/more nuanced thoughts and conclusions such as potential for bias at a large scale with large language models and generative AI causing harm<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>).</p>
<p>I&rsquo;m in an information gathering stage right now (if the knowledge contained in the brain of the world&rsquo;s leading expert on generative AI were represented by a complicated, elaborate, structurally sound bridge, my level of knowledge is a piece of rough lumber slapped between two puddles) so I don&rsquo;t have much to add to the discourse that is of consequence.</p>
<p>(But I&rsquo;m going to, anyway, because this is the internet!) Based on my observations, it seems that many laypeople have made a lot of assumptions about ChatGPT without ever having used it or read any of the materials from OpenAI. I know because I did that. I heard about it and saw some of the more ridiculous examples on social media and some news sites and such, and rolled my eyes a bit.</p>
<p>Then I figured if I&rsquo;m going to be skeptical and pooh-pooh an emerging technology, it would probably be good for me to try it out so I can REALLY knock it. So I did!</p>
<p>The first thing I asked ChatGPT was what happened to the <a href="https://chat.openai.com/share/6e40c218-8229-4d0f-9dd6-705927f72254">hole in the ozone layer</a><sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Its response <em>seemed</em> right, and I used Wikipedia as the source of truth to verify facts, like confirming that the Montreal Protocol was in fact adopted in 1987. Because if ChatGPT had told me it was 1989, I would have believed it.</p>
<p>Basically, it behaved mostly as I expected it to, and it was kind of useful, even with what I think is a healthy level of skepticism. I also appreciated that it&rsquo;s pretty clear from the various disclaimers that it can be wrong, dangerous, biased, etc.</p>
<p>I&rsquo;ve used it a lot more since then, asking for guidance on gift ideas for my notoriously hard-to-shop-for parents (I ended up going with my own initial idea, a gifted trip to the Korean spa, which actually was on ChatGPT&rsquo;s list as well), something thoughtful to say to a coworker about to go off on parental leave (I mostly used my own words except one suggestion from ChatGPT to encourage them to take care of themselves in addition to the baby), and, what has become a pretty frequent use case for me at work lately, debugging SQL queries.</p>
<p>My early conclusion based on this limited experience (since May I have used ChatGPT approximately once a day on average) is that ChatGPT is mostly like any other tool‚Äîif it&rsquo;s used for the right scenario in the right way, it can be incredibly useful, and if not, it can either just not add much value (best case scenario) or actively cause harm (worst case scenario). If I need a flathead screwdriver and all I have is a Philips head, the best decision I can make is to not use an inadequate and ineffective tool for my use case. Even if it&rsquo;s the fanciest, most technologically advanced Philips head screwdriver, powered by drill with wifi connectivity, rainbow LED lighting, and adorned with sparkles, it doesn&rsquo;t really matter if it&rsquo;s not the tool that I need.</p>
<p>What about disclosing use of ChatGPT as a tool? I think it depends. When I use it to debug a query, I don&rsquo;t necessarily report that out when reporting on whatever finding I was investigating in the first place. (I <em>have</em> been excitedly telling anyone who will listen to me that I&rsquo;ve been using ChatGPT to debug my SQL queries (and then the cleaning staff are like, please, lady, I just want to mop this floor, okay?), for whatever that&rsquo;s worth.) If it were being used for looking up and reporting on facts more quickly and easily (such as in publishing content), such as my ozone layer question, I would say it should absolutely be made explicitly clear that the content was generated using a tool developed based on a large language model and list the known limitations.</p>
<p>(I had a flashback to working with this one thoracic surgeon who was really adept with the surgical robot and kind of took issue at the operating room staff for insisting that his patients' informed consent documentation state SPECIFIC permission to do a robotic-assisted wedge resection of left lung or whatever, instead of just wedge resection of left lung, and his argument was that he doesn&rsquo;t have to get permission from the patient or even tell them if he were using a 11-blade versus a 15-blade; the robot was just a tool at his disposal and he as the surgeon had a responsibility to use the right tool for the job. I could see his point, but at the same time, it also didn&rsquo;t seem totally right to not have a documented conversation with the patient that the robot would be used‚Äîand of course he had had that conversation, but the OR staff didn&rsquo;t know that, so in that case maybe the informed consent was a tool being incorrectly used to represent all communication with the patient.)</p>
<p>ChatGPT seems to have the most potential for harm when there isn&rsquo;t reliable feedback on its accuracy (or if the user does not care to actively seek feedback). With a prompt like &ldquo;debug my SQL,&rdquo; I can immediately judge the quality of the response because either my SQL runs or it doesn&rsquo;t. For that lawyer who didn&rsquo;t verify that the case law ChatGPT quoted was real before submitting it in a court filing&hellip; oy.</p>
<p>Anyway, obviously we need to learn more, but with the right guardrails and oversight, we shouldn&rsquo;t fear technology. If anything, we should fear unchecked capitalism, because that&rsquo;s what has ruined and snuffed out a lot of the exciting potential that technology offers, but that&rsquo;s another story for another day.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>That is a joke about surgeons, the original gangsters in perfecting the art of being confidently wrong. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I&rsquo;m thinking of experts like Joy Buolamwini, Timnit Gebru, etc. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>The context is that I was talking to someone in their 20s and mentioned something about Aqua Net and CFCs and how we made a hole in the ozone layer real bad in the 1980s but then we fixed it, and they were like, &ldquo;What is the ozone layer?&rdquo; After I recovered from a mild generation gap-induced heart attack, I turned to the internet for help. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

</div>
  <footer class="post-footer">
  </footer>
</article>
    </main><footer class="footer">
    <div class="top">
        <span><a href="https://kwon.nyc/">Kwon.nyc</a> is made by me in Brooklyn</span>
        <span>&copy; 2023 <a href="mailto:kwon at fastmail.com">Rachel J. Kwon Í∂åÏñ¥ÏßÑ</a></span>

    </div>
    <div class="bottom-left">
        <span><a href="https://kwon.nyc/colophon">Colophon</a></span>
        <span><a href="https://kwon.nyc/notes/index.xml">RSS feed</a></span>
        <span><a href="https://github.com/rjkwon/personal">Source</a></span>
        <span><a href="mailto:kwon at fastmail.com">Email me</a></span>
    </div>
    <div class="bottom-right">
        <span><a rel="me" href="https://mastodon.social/@rjkwon">Mastodon</a></span>
        <span><a href="https://www.linkedin.com/in/rjkwon/">LinkedIn</a></span>
        <span><a href="https://www.last.fm/user/rjkwon">Last.fm</a></span>
        
    </div>   
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">‚òùÔ∏è
    </button>
</a>



<script defer src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>

</body>

</html>
